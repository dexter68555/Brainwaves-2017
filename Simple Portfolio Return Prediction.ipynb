{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":52,"outputs":[{"output_type":"stream","text":"/kaggle/input/returnrate/sample_submission.csv\n/kaggle/input/returnrate/test.csv\n/kaggle/input/returnrate/train.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error, r2_score","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepareData( train_df, test_df):\n    print(train_df.info())\n    data = train_df.values\n    test_data = test_df.values\n    \n    #if not train:\n    #    data = np.concatenate( (data , np.zeros(data.shape[0])) , axis=1)\n    X = data[: , 1:data.shape[1]-1]\n    Y = data[: , data.shape[1]-1]\n    print(X.shape, Y.shape)\n    X_Test = test_data[: , 1:test_data.shape[1]-1]\n    \n    \n    labEncoder = LabelEncoder()\n    labEncoder.fit(Y)\n    label_y = Y \n    \n    final_X = None\n    Test_X = None\n    for cnt in range(0 , X.shape[1]):\n        print(train_df.columns[cnt+1])\n        if train_df.columns[cnt+1].__contains__(\"status\") or train_df.columns[cnt+1].__contains__(\"hedge_value\") or train_df.columns[cnt+1].__contains__(\"indicator_code\") or train_df.columns[cnt+1].__contains__(\"bought\") or train_df.columns[cnt+1].__contains__(\"libor_rate\") or train_df.columns[cnt+1].__contains__(\"sold\") or train_df.columns[cnt+1].__contains__(\"start_date\") or train_df.columns[cnt+1].__contains__(\"euribor_rate\") or train_df.columns[cnt+1].__contains__(\"creation_date\") or train_df.columns[cnt+1].__contains__(\"sell_date\"):\n            print(\"non obj\")\n            \n            curFeature = X[:,cnt]\n            curFeature = curFeature.reshape(X.shape[0], 1)\n            \n            curTestFeature = X_Test[:,cnt]\n            curTestFeature = curTestFeature.reshape(X_Test.shape[0], 1)\n        else:\n            print(\"obj\")\n            labEncoder = LabelEncoder()\n            labEncoder.fit(np.append(X[:,cnt] , X_Test[:,cnt]))\n            curFeature = labEncoder.transform(X[:,cnt])\n            curFeature = curFeature.reshape(X.shape[0], 1)\n            \n            curTestFeature = labEncoder.transform(X_Test[:,cnt])\n            curTestFeature = curTestFeature.reshape(X_Test.shape[0], 1)\n            \n            \n            \n\n        if final_X is None:\n            final_X = curFeature\n        else:\n            final_X = np.concatenate((final_X , curFeature) , axis=1)\n        \n        \n        if Test_X is None:\n            Test_X = curTestFeature\n        else:\n            Test_X = np.concatenate((Test_X , curTestFeature) , axis=1)\n        \n    seed = 8\n    test_size = .1\n    X_train, X_test, Y_train, Y_test = train_test_split(final_X, label_y, test_size=test_size,\n                                                        random_state=seed)\n\n    \n\n    return X_train, X_test, Y_train, Y_test , Test_X","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepareDataByPandas(train_df , test_df):\n    modArr = dict()\n    for colNam in train_df.columns:\n        mod = train_df[colNam].mode()[0]\n        modArr[colNam] = mod\n    \n    for colNam in train_df.columns:\n        train_df[colNam].fillna(modArr[colNam] , inplace=True)\n    \n    for colNam in test_df.columns:\n        test_df[colNam].fillna(modArr[colNam] , inplace=True)\n    \n    \n    \n    return prepareData(train_df,test_df)","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/returnrate/train.csv')\ntest = pd.read_csv('../input/returnrate/test.csv')\nsub = pd.read_csv('../input/returnrate/sample_submission.csv')\n\ntrain.rename(columns={\"return\": \"returnrate\"}, inplace=True)\ntest['returnrate'] = 0\n\ntrain.drop(\"portfolio_id\", axis = 1, inplace = True)\ntest.drop(\"portfolio_id\", axis = 1, inplace = True)\n\ntrain.drop(\"desk_id\", axis = 1, inplace = True)\ntest.drop(\"desk_id\", axis = 1, inplace = True)\n\ntrain.drop(\"office_id\", axis = 1, inplace = True)\ntest.drop(\"office_id\", axis = 1, inplace = True)\n\nprint(train.head())\nprint(test.head())","execution_count":63,"outputs":[{"output_type":"stream","text":"       desk_id    office_id pf_category  start_date         sold country_code  \\\n0  DSK00001001  OFF00001002           B    20040720  110000000.0            T   \n1  DSK00001002  OFF00001001           A    20040709  176671000.0            N   \n2  DSK00001004  OFF00001001           A    20040723   56474000.0            T   \n3  DSK00001005  OFF00001001           A    20040609  164813000.0            T   \n4  DSK00001005  OFF00001002           B    20040609  140800000.0            T   \n\n   euribor_rate currency  libor_rate        bought  creation_date  \\\n0       0.02074      USD    2.332216  1.098097e+08       20040720   \n1       0.02074      GBP    5.269617  1.760084e+08       20040723   \n2       0.02074      USD    2.332216  5.637953e+07       20040723   \n3       0.02074      USD    2.332216  1.645088e+08       20040723   \n4       0.02074      USD    2.332216  1.405402e+08       20040723   \n\n  indicator_code  sell_date type hedge_value status  returnrate  \n0            NaN   20040812    B         NaN    NaN     0.02496  \n1            NaN   20040812    C         NaN    NaN     0.05496  \n2            NaN   20040817    A         NaN    NaN     0.02496  \n3            NaN   20040713    A         NaN    NaN     0.02496  \n4            NaN   20040713    B         NaN    NaN     0.02496  \n       desk_id    office_id pf_category  start_date         sold country_code  \\\n0  DSK00001001  OFF00001001           A    20040720  171831000.0            T   \n1  DSK00001003  OFF00001002           B    20040723   56485000.0            T   \n2  DSK00001007  OFF00001001           A    20040607   41734000.0            T   \n3  DSK00001011  OFF00001001           A    20040716   82951000.0            T   \n4  DSK00001012  OFF00001001           A    20040713   73293000.0            T   \n\n   euribor_rate currency  libor_rate        bought  creation_date  \\\n0       0.02074      USD    2.332216  1.715337e+08       20040720   \n1       0.02074      USD    2.332216  5.638038e+07       20040723   \n2       0.02074      USD    2.332216  4.166179e+07       20040726   \n3       0.02074      USD    2.332216  8.250936e+07       20040726   \n4       0.02074      USD    2.332216  7.317055e+07       20040726   \n\n  indicator_code  sell_date type hedge_value status  returnrate  \n0            NaN   20040812    A         NaN    NaN           0  \n1            NaN   20040719    B         NaN    NaN           0  \n2            NaN   20040709    A         NaN    NaN           0  \n3            NaN   20041019    A         NaN    NaN           0  \n4            NaN   20040813    A         NaN    NaN           0  \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test , actual_test = prepareDataByPandas(train , test)","execution_count":57,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9366 entries, 0 to 9365\nData columns (total 18 columns):\nportfolio_id      9366 non-null object\ndesk_id           9366 non-null object\noffice_id         9366 non-null object\npf_category       9366 non-null object\nstart_date        9366 non-null int64\nsold              9366 non-null float64\ncountry_code      9366 non-null object\neuribor_rate      9366 non-null float64\ncurrency          9366 non-null object\nlibor_rate        9366 non-null float64\nbought            9366 non-null float64\ncreation_date     9366 non-null int64\nindicator_code    9366 non-null bool\nsell_date         9366 non-null int64\ntype              9366 non-null object\nhedge_value       9366 non-null bool\nstatus            9366 non-null bool\nreturnrate        9366 non-null float64\ndtypes: bool(3), float64(5), int64(3), object(7)\nmemory usage: 1.1+ MB\nNone\n(9366, 16) (9366,)\ndesk_id\nobj\noffice_id\nobj\npf_category\nobj\nstart_date\nnon obj\nsold\nnon obj\ncountry_code\nobj\neuribor_rate\nnon obj\ncurrency\nobj\nlibor_rate\nnon obj\nbought\nnon obj\ncreation_date\nnon obj\nindicator_code\nnon obj\nsell_date\nnon obj\ntype\nobj\nhedge_value\nnon obj\nstatus\nnon obj\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = LGBMRegressor(max_depth=3,silent=False)\nmodel = LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.01, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11, max_depth=3)\nmodel.fit(x_train, y_train)","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n              boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n              feature_fraction=0.2319, feature_fraction_seed=9,\n              importance_type='split', learning_rate=0.01, max_bin=55,\n              max_depth=3, min_child_samples=20, min_child_weight=0.001,\n              min_data_in_leaf=6, min_split_gain=0.0,\n              min_sum_hessian_in_leaf=11, n_estimators=720, n_jobs=-1,\n              num_leaves=5, objective='regression', random_state=None,\n              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n              subsample_for_bin=200000, subsample_freq=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.concatenate((y_pred.reshape(len(y_pred) ,1) , y_test.reshape(len(y_pred) ,1)), axis=1)\n\ndef Average(lst): \n    return sum(lst) / len(lst) \n\n# The mean squared error\nprint(\"Mean squared error: %.2f\"\n      % mean_squared_error(y_test, y_pred))\n\n# Mean of y_test\nprint(\"Mean: %.2f\"\n      % Average(y_test))\n\nprint('Variance score: %.2f' % r2_score(y_test, y_pred))","execution_count":60,"outputs":[{"output_type":"stream","text":"Mean squared error: 0.00\nMean: 0.01\nVariance score: 0.96\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}