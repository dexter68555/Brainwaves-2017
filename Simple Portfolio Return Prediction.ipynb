{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\n\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error, r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepareData( train_df, test_df):\n    print(train_df.info())\n    data = train_df.values\n    test_data = test_df.values\n    \n    #if not train:\n    #    data = np.concatenate( (data , np.zeros(data.shape[0])) , axis=1)\n    X = data[: , 1:data.shape[1]-1]\n    Y = data[: , data.shape[1]-1]\n    print(X.shape, Y.shape)\n    X_Test = test_data[: , 1:test_data.shape[1]-1]\n    \n    \n    labEncoder = LabelEncoder()\n    labEncoder.fit(Y)\n    label_y = Y \n    \n    final_X = None\n    Test_X = None\n    for cnt in range(0 , X.shape[1]):\n        print(train_df.columns[cnt+1])\n        if train_df.columns[cnt+1].__contains__(\"status\") or train_df.columns[cnt+1].__contains__(\"hedge_value\") or train_df.columns[cnt+1].__contains__(\"indicator_code\") or train_df.columns[cnt+1].__contains__(\"bought\") or train_df.columns[cnt+1].__contains__(\"libor_rate\") or train_df.columns[cnt+1].__contains__(\"sold\") or train_df.columns[cnt+1].__contains__(\"start_date\") or train_df.columns[cnt+1].__contains__(\"euribor_rate\") or train_df.columns[cnt+1].__contains__(\"creation_date\") or train_df.columns[cnt+1].__contains__(\"sell_date\"):\n            print(\"non obj\")\n            \n            curFeature = X[:,cnt]\n            curFeature = curFeature.reshape(X.shape[0], 1)\n            \n            curTestFeature = X_Test[:,cnt]\n            curTestFeature = curTestFeature.reshape(X_Test.shape[0], 1)\n        else:\n            print(\"obj\")\n            labEncoder = LabelEncoder()\n            labEncoder.fit(np.append(X[:,cnt] , X_Test[:,cnt]))\n            curFeature = labEncoder.transform(X[:,cnt])\n            curFeature = curFeature.reshape(X.shape[0], 1)\n            \n            curTestFeature = labEncoder.transform(X_Test[:,cnt])\n            curTestFeature = curTestFeature.reshape(X_Test.shape[0], 1)\n            \n            \n            \n\n        if final_X is None:\n            final_X = curFeature\n        else:\n            final_X = np.concatenate((final_X , curFeature) , axis=1)\n        \n        \n        if Test_X is None:\n            Test_X = curTestFeature\n        else:\n            Test_X = np.concatenate((Test_X , curTestFeature) , axis=1)\n        \n    seed = 8\n    test_size = .1\n    X_train, X_test, Y_train, Y_test = train_test_split(final_X, label_y, test_size=test_size,\n                                                        random_state=seed)\n\n    \n\n    return X_train, X_test, Y_train, Y_test , Test_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepareDataByPandas(train_df , test_df):\n    modArr = dict()\n    for colNam in train_df.columns:\n        mod = train_df[colNam].mode()[0]\n        modArr[colNam] = mod\n    \n    for colNam in train_df.columns:\n        train_df[colNam].fillna(modArr[colNam] , inplace=True)\n    \n    for colNam in test_df.columns:\n        test_df[colNam].fillna(modArr[colNam] , inplace=True)\n    \n    \n    \n    return prepareData(train_df,test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/returnrate/train.csv')\ntest = pd.read_csv('../input/returnrate/test.csv')\nsub = pd.read_csv('../input/returnrate/sample_submission.csv')\n\ntrain.rename(columns={\"return\": \"returnrate\"}, inplace=True)\ntest['returnrate'] = 0\n\ntrain.drop(\"portfolio_id\", axis = 1, inplace = True)\ntest.drop(\"portfolio_id\", axis = 1, inplace = True)\n\ntrain.drop(\"desk_id\", axis = 1, inplace = True)\ntest.drop(\"desk_id\", axis = 1, inplace = True)\n\ntrain.drop(\"office_id\", axis = 1, inplace = True)\ntest.drop(\"office_id\", axis = 1, inplace = True)\n\nprint(train.head())\nprint(test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test , actual_test = prepareDataByPandas(train , test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = LGBMRegressor(max_depth=3,silent=False)\nmodel = LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.01, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11, max_depth=3)\nmodel.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.concatenate((y_pred.reshape(len(y_pred) ,1) , y_test.reshape(len(y_pred) ,1)), axis=1)\n\ndef Average(lst): \n    return sum(lst) / len(lst) \n\n# The mean squared error\nprint(\"Mean squared error: %.2f\"\n      % mean_squared_error(y_test, y_pred))\n\n# Mean of y_test\nprint(\"Mean: %.2f\"\n      % Average(y_test))\n\nprint('Variance score: %.2f' % r2_score(y_test, y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}